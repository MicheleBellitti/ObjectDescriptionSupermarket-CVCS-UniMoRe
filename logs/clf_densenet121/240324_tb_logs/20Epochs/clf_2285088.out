Starting clf_train.py 

Starting clf_test.py 

Inference images and results saved.
Starting clf_evaluate.py 

Classification Report:
               precision    recall  f1-score   support

           0      0.777     0.996     0.873       276
           1      0.905     0.950     0.927        40
           2      0.978     1.000     0.989        44
           3      1.000     0.711     0.831        45
           4      0.692     0.439     0.537        41
           5      0.700     0.233     0.350        30
           6      0.727     0.516     0.604        31
           7      0.929     0.941     0.935       153
           8      0.808     0.600     0.689        35
           9      0.506     0.786     0.615        56
          10      0.833     0.952     0.889        21
          11      0.824     0.519     0.636        27
          12      0.970     0.889     0.928        36
          13      0.943     0.769     0.847       108
          14      0.852     0.920     0.885        25
          15      1.000     0.909     0.952        22
          16      1.000     0.440     0.611        25
          17      0.714     0.735     0.725        34
          18      0.673     0.515     0.583        68
          19      1.000     0.995     0.998       219
          20      0.976     1.000     0.988       164
          21      0.909     1.000     0.952        30
          22      1.000     0.903     0.949        31
          23      1.000     0.902     0.949        41
          24      0.950     1.000     0.974        19
          25      1.000     1.000     1.000        47
          26      0.983     1.000     0.991        58
          27      0.983     1.000     0.991       172
          28      0.778     1.000     0.875        14
          29      1.000     1.000     1.000        22
          30      1.000     0.895     0.944        19
          31      0.976     0.976     0.976        42
          32      1.000     0.704     0.826        27
          33      1.000     1.000     1.000        25
          34      1.000     0.667     0.800        15
          35      0.944     0.810     0.872        21
          36      0.907     1.000     0.951        39
          37      0.971     0.892     0.930        37
          38      0.940     0.991     0.965       110
          39      0.880     0.943     0.910        70
          40      0.895     1.000     0.944        17
          41      0.980     0.990     0.985       100
          42      0.800     0.966     0.875        29

    accuracy                          0.898      2485
   macro avg      0.900     0.848     0.862      2485
weighted avg      0.904     0.898     0.893      2485

