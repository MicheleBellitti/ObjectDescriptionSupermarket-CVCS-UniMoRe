Starting clf_train.py 

Starting clf_test.py 

Inference images and results saved.
Starting clf_evaluate.py 

Classification Report:
               precision    recall  f1-score   support

           0      0.820     0.993     0.898       276
           1      0.929     0.975     0.951        40
           2      0.957     1.000     0.978        44
           3      0.974     0.844     0.905        45
           4      0.750     0.585     0.658        41
           5      0.800     0.267     0.400        30
           6      0.812     0.419     0.553        31
           7      0.933     0.915     0.924       153
           8      1.000     0.600     0.750        35
           9      0.578     0.661     0.617        56
          10      0.724     1.000     0.840        21
          11      0.895     0.630     0.739        27
          12      0.944     0.944     0.944        36
          13      0.845     0.806     0.825       108
          14      0.955     0.840     0.894        25
          15      1.000     0.818     0.900        22
          16      1.000     0.720     0.837        25
          17      0.632     0.706     0.667        34
          18      0.758     0.735     0.746        68
          19      0.991     0.995     0.993       219
          20      0.976     1.000     0.988       164
          21      1.000     1.000     1.000        30
          22      1.000     1.000     1.000        31
          23      1.000     0.805     0.892        41
          24      1.000     0.947     0.973        19
          25      1.000     1.000     1.000        47
          26      1.000     1.000     1.000        58
          27      0.961     1.000     0.980       172
          28      0.889     0.571     0.696        14
          29      0.880     1.000     0.936        22
          30      0.941     0.842     0.889        19
          31      1.000     0.952     0.976        42
          32      0.783     0.667     0.720        27
          33      1.000     0.880     0.936        25
          34      0.778     0.467     0.583        15
          35      0.750     1.000     0.857        21
          36      0.760     0.974     0.854        39
          37      0.921     0.946     0.933        37
          38      0.940     0.991     0.965       110
          39      0.919     0.971     0.944        70
          40      0.789     0.882     0.833        17
          41      0.960     0.970     0.965       100
          42      0.815     0.759     0.786        29

    accuracy                          0.900      2485
   macro avg      0.892     0.839     0.854      2485
weighted avg      0.904     0.900     0.896      2485

