Starting clf_train.py 

Starting clf_test.py 

Inference images and results saved.
Starting clf_evaluate.py 

Classification Report:
               precision    recall  f1-score   support

           0      0.845     0.989     0.912       276
           1      0.925     0.925     0.925        40
           2      1.000     1.000     1.000        44
           3      0.971     0.756     0.850        45
           4      0.719     0.561     0.630        41
           5      0.529     0.300     0.383        30
           6      0.704     0.613     0.655        31
           7      0.961     0.954     0.957       153
           8      0.742     0.657     0.697        35
           9      0.479     0.804     0.600        56
          10      0.870     0.952     0.909        21
          11      0.833     0.556     0.667        27
          12      0.970     0.889     0.928        36
          13      0.924     0.898     0.911       108
          14      0.885     0.920     0.902        25
          15      1.000     0.909     0.952        22
          16      0.941     0.640     0.762        25
          17      0.812     0.382     0.520        34
          18      0.692     0.529     0.600        68
          19      0.995     1.000     0.998       219
          20      0.976     1.000     0.988       164
          21      1.000     1.000     1.000        30
          22      1.000     1.000     1.000        31
          23      1.000     0.902     0.949        41
          24      0.950     1.000     0.974        19
          25      1.000     1.000     1.000        47
          26      1.000     1.000     1.000        58
          27      0.989     1.000     0.994       172
          28      0.824     1.000     0.903        14
          29      1.000     1.000     1.000        22
          30      1.000     0.895     0.944        19
          31      1.000     0.976     0.988        42
          32      0.941     0.593     0.727        27
          33      1.000     0.960     0.980        25
          34      0.875     0.467     0.609        15
          35      0.950     0.905     0.927        21
          36      0.830     1.000     0.907        39
          37      0.972     0.946     0.959        37
          38      0.964     0.964     0.964       110
          39      0.893     0.957     0.924        70
          40      0.850     1.000     0.919        17
          41      0.952     1.000     0.976       100
          42      0.778     0.966     0.862        29

    accuracy                          0.907      2485
   macro avg      0.896     0.855     0.866      2485
weighted avg      0.911     0.907     0.903      2485

