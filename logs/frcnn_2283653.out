True
device: cuda
TrueTrueTrue


device:device:device:   cudacudacuda


[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mModifications to default arguments:
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16
[34mFor a complete table of recommended hyperparameters, see
[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.
[0m
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.Weight decoupling enabled in AdaBelief[31mModifications to default arguments:


[31mModifications to default arguments:Rectification enabled in AdaBelief
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True
[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True

[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16[31mModifications to default arguments:


[34mFor a complete table of recommended hyperparameters, see[34mFor a complete table of recommended hyperparameters, see

[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer
[31m                           eps  weight_decouple    rectify
-----------------------  -----  -----------------  ---------
adabelief-pytorch=0.0.5  1e-08  False              False
>=0.1.0 (Current 0.2.0)  1e-16  True               True[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.


[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)
----------------------------------------------------------  ----------------------------------------------
Recommended eps = 1e-8                                      Recommended eps = 1e-16[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.[0m


[34mFor a complete table of recommended hyperparameters, see[0m

Weight decoupling enabled in AdaBelief[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer

[32mYou can disable the log message by setting "print_change_log = False", though it is recommended to keep as a reminder.Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief

[0mRectification enabled in AdaBelief

Weight decoupling enabled in AdaBelief
Rectification enabled in AdaBelief
Training Epoch: 0 [174/175] Loss: 0.8908 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 0 [174/175] Loss: 1.0373 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 0 [174/175] Loss: 0.9443 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 0 [174/175] Loss: 0.9279 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 0 [10/11] Loss: 4.3466 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 0 [10/11] Loss: 4.8414 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 0 [10/11] Loss: 4.1425 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 0 [10/11] Loss: 3.4904 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 1 [174/175] Loss: 0.8606 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 1 [174/175] Loss: 0.8883 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 1 [174/175] Loss: 0.9228 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 1 [174/175] Loss: 0.9145 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 1 [10/11] Loss: 4.0036 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 1 [10/11] Loss: 4.1692 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 1 [10/11] Loss: 4.4622 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 1 [10/11] Loss: 4.4089 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 2 [174/175] Loss: 0.9954 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 2 [174/175] Loss: 0.7765 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 2 [174/175] Loss: 0.6758 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 2 [174/175] Loss: 0.8237 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 2 [10/11] Loss: 4.2412 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 2 [10/11] Loss: 3.5836 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 2 [10/11] Loss: 4.1412 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 2 [10/11] Loss: 3.7388 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 3 [174/175] Loss: 0.7418 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 3 [174/175] Loss: 0.5585 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 3 [174/175] Loss: 0.7761 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 3 [174/175] Loss: 0.7643 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 3 [10/11] Loss: 4.3797 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 3 [10/11] Loss: 4.0815 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 3 [10/11] Loss: 4.0641 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 3 [10/11] Loss: 4.2706 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 4 [174/175] Loss: 0.6968 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 4 [174/175] Loss: 0.6867 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 4 [174/175] Loss: 0.6366 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 4 [174/175] Loss: 0.5845 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 4 [10/11] Loss: 4.5767 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 4 [10/11] Loss: 4.0666 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 4 [10/11] Loss: 3.7925 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 4 [10/11] Loss: 4.8185 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 5 [174/175] Loss: 0.8548 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 5 [174/175] Loss: 1.1364 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 5 [174/175] Loss: 0.6981 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 5 [174/175] Loss: 0.6099 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 5 [10/11] Loss: 4.3130 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 5 [10/11] Loss: 4.6537 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 5 [10/11] Loss: 3.9655 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 5 [10/11] Loss: 4.6118 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 6 [174/175] Loss: 0.7525 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 6 [174/175] Loss: 0.6931 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 6 [174/175] Loss: 0.6833 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 6 [174/175] Loss: 0.7795 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 6 [10/11] Loss: 4.4881 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 6 [10/11] Loss: 4.1602 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 6 [10/11] Loss: 4.7429 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 6 [10/11] Loss: 3.8050 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 7 [174/175] Loss: 0.5917 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 7 [174/175] Loss: 0.6254 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 7 [174/175] Loss: 0.6962 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 7 [174/175] Loss: 0.6964 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 7 [10/11] Loss: 4.2024 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 7 [10/11] Loss: 4.5512 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 7 [10/11] Loss: 4.1706 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 7 [10/11] Loss: 3.9279 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 8 [174/175] Loss: 0.7643 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 8 [174/175] Loss: 0.6508 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 8 [174/175] Loss: 0.6187 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 8 [174/175] Loss: 0.5684 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 8 [10/11] Loss: 4.1088 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Validating Epoch: 8 [10/11] Loss: 4.6346 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Validating Epoch: 8 [10/11] Loss: 3.8906 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Validating Epoch: 8 [10/11] Loss: 4.0984 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Training Epoch: 9 [174/175] Loss: 0.5548 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 9 [174/175] Loss: 0.5388 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 9 [174/175] Loss: 0.5963 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 9 [174/175] Loss: 0.3906 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 9 [10/11] Loss: 5.3430 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 9 [10/11] Loss: 4.8216 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 9 [10/11] Loss: 4.9285 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 9 [10/11] Loss: 3.5272 ━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 10 [174/175] Loss: 0.6059 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 10 [174/175] Loss: 0.5849 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 10 [174/175] Loss: 0.5636 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 10 [174/175] Loss: 0.5882 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 10 [10/11] Loss: 5.0999 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 10 [10/11] Loss: 4.5595 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 10 [10/11] Loss: 4.9989 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 10 [10/11] Loss: 4.1519 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 11 [174/175] Loss: 0.5410 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 11 [174/175] Loss: 0.4332 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 11 [174/175] Loss: 0.4663 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 11 [174/175] Loss: 0.6781 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 11 [10/11] Loss: 5.3938 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 11 [10/11] Loss: 4.5129 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 11 [10/11] Loss: 3.9273 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 11 [10/11] Loss: 4.2557 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 12 [174/175] Loss: 0.4962 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 12 [174/175] Loss: 0.6050 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 12 [174/175] Loss: 0.5595 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 12 [174/175] Loss: 0.4939 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 12 [10/11] Loss: 4.7175 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 12 [10/11] Loss: 5.0476 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 12 [10/11] Loss: 5.0761 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 12 [10/11] Loss: 4.6039 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 13 [174/175] Loss: 0.5410 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 13 [174/175] Loss: 0.4499 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 13 [174/175] Loss: 0.5462 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 13 [174/175] Loss: 0.5939 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 13 [10/11] Loss: 5.0937 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 13 [10/11] Loss: 4.6602 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 13 [10/11] Loss: 4.4144 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 13 [10/11] Loss: 4.9603 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 14 [174/175] Loss: 0.5698 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 14 [174/175] Loss: 0.5796 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 14 [174/175] Loss: 0.4858 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 14 [174/175] Loss: 0.4926 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 14 [10/11] Loss: 5.1334 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Validating Epoch: 14 [10/11] Loss: 4.3944 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Validating Epoch: 14 [10/11] Loss: 4.3886 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Validating Epoch: 14 [10/11] Loss: 5.0024 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Training Epoch: 15 [174/175] Loss: 0.4530 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 15 [174/175] Loss: 0.7167 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 15 [174/175] Loss: 0.6323 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Training Epoch: 15 [174/175] Loss: 0.6140 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 15 [10/11] Loss: 5.7964 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 15 [10/11] Loss: 4.9822 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 15 [10/11] Loss: 4.9967 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Validating Epoch: 15 [10/11] Loss: 4.9510 ━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
