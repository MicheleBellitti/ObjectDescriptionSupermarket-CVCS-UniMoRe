Starting clf_evaluate.py 

Classification Report:
               precision    recall  f1-score   support

           0      0.861     0.989     0.921       276
           1      0.974     0.925     0.949        40
           2      1.000     0.932     0.965        44
           3      0.977     0.956     0.966        45
           4      0.786     0.537     0.638        41
           5      0.727     0.533     0.615        30
           6      0.826     0.613     0.704        31
           7      0.966     0.928     0.947       153
           8      0.882     0.857     0.870        35
           9      0.527     0.518     0.523        56
          10      0.724     1.000     0.840        21
          11      0.870     0.741     0.800        27
          12      1.000     0.917     0.957        36
          13      0.967     0.824     0.890       108
          14      0.957     0.880     0.917        25
          15      0.909     0.909     0.909        22
          16      1.000     0.880     0.936        25
          17      0.579     0.647     0.611        34
          18      0.639     0.676     0.657        68
          19      0.995     1.000     0.998       219
          20      1.000     1.000     1.000       164
          21      1.000     0.967     0.983        30
          22      1.000     1.000     1.000        31
          23      1.000     0.854     0.921        41
          24      1.000     1.000     1.000        19
          25      1.000     1.000     1.000        47
          26      1.000     1.000     1.000        58
          27      0.950     1.000     0.975       172
          28      0.650     0.929     0.765        14
          29      0.917     1.000     0.957        22
          30      1.000     1.000     1.000        19
          31      0.976     0.952     0.964        42
          32      0.955     0.778     0.857        27
          33      0.926     1.000     0.962        25
          34      1.000     0.800     0.889        15
          35      0.826     0.905     0.864        21
          36      0.929     1.000     0.963        39
          37      0.947     0.973     0.960        37
          38      0.982     0.982     0.982       110
          39      0.957     0.943     0.950        70
          40      0.944     1.000     0.971        17
          41      0.961     0.990     0.975       100
          42      0.933     0.966     0.949        29

    accuracy                          0.920      2485
   macro avg      0.907     0.891     0.895      2485
weighted avg      0.922     0.920     0.918      2485

